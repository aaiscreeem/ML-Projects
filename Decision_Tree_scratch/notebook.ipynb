{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_excel(\"C:/Users/adity/A2 ML/Train.xlsx\")\n",
    "df['y'] = df['y'].replace({'yes': 1, 'no': 0})\n",
    "# df = df.drop('day', axis=1)\n",
    "\n",
    "# day had barely any correlation with y and would have caused overfitting. However it was later clarified that we can't drop features\n",
    "\n",
    "# balance_mean = df['balance'].mean()\n",
    "# balance_std = df['balance'].std()\n",
    "\n",
    "# duration_mean = df['duration'].mean()\n",
    "# duration_std = df['duration'].std()\n",
    "\n",
    "# df['balance'] = (df['balance'] - balance_mean) / balance_std\n",
    "# df['duration'] = (df['duration'] - duration_mean) / duration_std\n",
    "\n",
    "#scaling just took extra time and provided no benefit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for feature: job\n",
      "                y=0   y=1     ratio\n",
      "job                                \n",
      "admin.         4540   631  0.877973\n",
      "blue-collar    9024   708  0.927250\n",
      "entrepreneur   1364   123  0.917283\n",
      "housemaid      1131   109  0.912097\n",
      "management     8157  1301  0.862444\n",
      "retired        1748   516  0.772085\n",
      "self-employed  1392   187  0.881571\n",
      "services       3785   369  0.911170\n",
      "student         669   269  0.713220\n",
      "technician     6757   840  0.889430\n",
      "unemployed     1101   202  0.844973\n",
      "unknown         254    34  0.881944\n",
      "\n",
      "\n",
      "Counts for feature: marital\n",
      "            y=0   y=1     ratio\n",
      "marital                        \n",
      "divorced   4585   622  0.880545\n",
      "married   24459  2755  0.898765\n",
      "single    10878  1912  0.850508\n",
      "\n",
      "\n",
      "Counts for feature: education\n",
      "             y=0   y=1     ratio\n",
      "education                       \n",
      "primary     6260   591  0.913735\n",
      "secondary  20752  2450  0.894406\n",
      "tertiary   11305  1996  0.849936\n",
      "unknown     1605   252  0.864297\n",
      "\n",
      "\n",
      "Counts for feature: default\n",
      "           y=0   y=1     ratio\n",
      "default                       \n",
      "no       39159  5237  0.882039\n",
      "yes        763    52  0.936196\n",
      "\n",
      "\n",
      "Counts for feature: housing\n",
      "           y=0   y=1     ratio\n",
      "housing                       \n",
      "no       16727  3354  0.832976\n",
      "yes      23195  1935  0.923000\n",
      "\n",
      "\n",
      "Counts for feature: loan\n",
      "        y=0   y=1     ratio\n",
      "loan                       \n",
      "no    33162  4805  0.873443\n",
      "yes    6760   484  0.933186\n",
      "\n",
      "\n",
      "Counts for feature: contact\n",
      "             y=0   y=1     ratio\n",
      "contact                         \n",
      "cellular   24916  4369  0.850811\n",
      "telephone   2516   390  0.865795\n",
      "unknown    12490   530  0.959293\n",
      "\n",
      "\n",
      "Counts for feature: poutcome\n",
      "            y=0   y=1     ratio\n",
      "poutcome                       \n",
      "failure    4283   618  0.873903\n",
      "other      1533   307  0.833152\n",
      "success     533   978  0.352747\n",
      "unknown   33573  3386  0.908385\n",
      "\n",
      "\n",
      "Counts for feature: month\n",
      "         y=0  y=1     ratio\n",
      "month                      \n",
      "apr     2355  577  0.803206\n",
      "aug     5559  688  0.889867\n",
      "dec      114  100  0.532710\n",
      "feb     2208  441  0.833522\n",
      "jan     1261  142  0.898788\n",
      "jul     6268  627  0.909065\n",
      "jun     4795  546  0.897772\n",
      "mar      229  248  0.480084\n",
      "may    12841  925  0.932805\n",
      "nov     3567  403  0.898489\n",
      "oct      415  323  0.562331\n",
      "sep      310  269  0.535406\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome','month']\n",
    "\n",
    "for feature in features:\n",
    "    print(f\"Counts for feature: {feature}\")\n",
    "    counts = df.groupby([feature, 'y']).size().unstack(fill_value=0)\n",
    "    counts.columns = ['y=0', 'y=1']\n",
    "    counts['ratio']=counts['y=0']/(counts['y=0']+counts['y=1'])\n",
    "    print(counts)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  marital  education default  balance housing loan  contact  day  \\\n",
      "0   58  married   tertiary      no     2143     yes   no  unknown    5   \n",
      "1   44   single  secondary      no       29     yes   no  unknown    5   \n",
      "2   33  married  secondary      no        2     yes  yes  unknown    5   \n",
      "3   47  married    unknown      no     1506     yes   no  unknown    5   \n",
      "4   33   single    unknown      no        1      no   no  unknown    5   \n",
      "\n",
      "   duration  campaign  pdays  previous poutcome      job_group month_group  y  \n",
      "0       261         1     -1         0  unknown   white-collar     may-aug  0  \n",
      "1       151         1     -1         0  unknown   white-collar     may-aug  0  \n",
      "2        76         1     -1         0  unknown  Self-employed     may-aug  0  \n",
      "3        92         1     -1         0  unknown    Blue-collar     may-aug  0  \n",
      "4       198         1     -1         0  unknown        Unknown     may-aug  0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Job group mapping\n",
    "job_group_mapping = {\n",
    "    'admin.': 'white-collar',\n",
    "    'management': 'white-collar',\n",
    "    'technician': 'white-collar',\n",
    "    'blue-collar': 'Blue-collar',\n",
    "    'services': 'Blue-collar',\n",
    "    'housemaid': 'Blue-collar',\n",
    "    'entrepreneur': 'Self-employed',\n",
    "    'self-employed': 'Self-employed',\n",
    "    'student': 'Student',\n",
    "    'unemployed': 'Unemployed',\n",
    "    'unknown': 'Unknown',\n",
    "    'retired': 'Retired'\n",
    "}\n",
    "\n",
    "df['job_group'] = df['job'].map(job_group_mapping)\n",
    "\n",
    "# Month group mapping\n",
    "month_group_mapping = {\n",
    "    'jan': 'jan-feb',\n",
    "    'feb': 'jan-feb',\n",
    "    'mar': 'mar',\n",
    "    'apr': 'apr',\n",
    "    'may': 'may-aug',  \n",
    "    'jun': 'may-aug',  \n",
    "    'jul': 'may-aug',  \n",
    "    'aug': 'may-aug',  \n",
    "    'sep': 'sep-oct',\n",
    "    'oct': 'sep-oct',\n",
    "    'nov': 'nov',\n",
    "    'dec': 'dec'\n",
    "}\n",
    "\n",
    "df['month_group'] = df['month'].map(month_group_mapping)\n",
    "\n",
    "# Drop the original 'job' and 'month' columns\n",
    "df = df.drop('job', axis=1)\n",
    "df = df.drop('month', axis=1)\n",
    "\n",
    "y_column = df.pop('y')\n",
    "df['y'] = y_column\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age              77\n",
      "marital           3\n",
      "education         4\n",
      "default           2\n",
      "balance        7168\n",
      "housing           2\n",
      "loan              2\n",
      "contact           3\n",
      "day              31\n",
      "duration       1573\n",
      "campaign         48\n",
      "pdays           559\n",
      "previous         41\n",
      "poutcome          4\n",
      "job_group         7\n",
      "month_group       7\n",
      "y                 2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_counts = df.nunique()\n",
    "print(unique_counts)\n",
    "\n",
    "def most_common_value(y):\n",
    "    count_dict = {}\n",
    "    for val in y:\n",
    "        if val in count_dict:\n",
    "            count_dict[val] += 1\n",
    "        else:\n",
    "            count_dict[val] = 1\n",
    "\n",
    "    most_common = None\n",
    "    max_count = -1\n",
    "    \n",
    "    for key, count in count_dict.items():\n",
    "        if count > max_count:\n",
    "            most_common = key\n",
    "            max_count = count\n",
    "    \n",
    "    return most_common\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None, n_samples=None, impurity=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold  # number in case of numerical, string in case of categorical\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value  # Only set for leaf nodes\n",
    "        self.n_samples = n_samples  \n",
    "        self.impurity= impurity  # for leaf nodes  \n",
    "    \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=10, min_gain=0, criterion=\"gini\", _class_weight=1.0):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.min_gain = min_gain\n",
    "        self.criterion = criterion  # \"gini\" or \"entropy\"\n",
    "        self.root = None\n",
    "        self._class_weight = _class_weight  # Weight of y=1 relative to y=0\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.root = self._grow_tree(X, y)\n",
    "        \n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples = X.shape[0]\n",
    "        n_labels = len(np.unique(y))\n",
    "        \n",
    "        # Stopping criteria\n",
    "        if depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split:\n",
    "            value = most_common_value(y)\n",
    "            if self.criterion == \"gini\":\n",
    "                Impurity = self._gini(y)  \n",
    "            else:\n",
    "                Impurity = self._entropy(y)  \n",
    "            \n",
    "            # Return a leaf node with the calculated impurity\n",
    "            return Node(value=value, n_samples=n_samples, impurity=Impurity)\n",
    "        \n",
    "        best_feature, best_threshold, best_gain = self._best_split(X, y)\n",
    "        \n",
    "        # Stop if no split is good enough\n",
    "        if best_gain < self.min_gain:\n",
    "            value = most_common_value(y)\n",
    "            \n",
    "            if self.criterion == \"gini\":\n",
    "                Impurity = self._gini(y)\n",
    "            else:\n",
    "                Impurity = self._entropy(y)\n",
    "            \n",
    "            return Node(value=value, n_samples=n_samples, impurity=Impurity)\n",
    "        \n",
    "        left_idxs, right_idxs = self._split(X[:, best_feature], best_threshold)\n",
    "        \n",
    "        # Recurse\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "        \n",
    "        return Node(feature=best_feature, threshold=best_threshold, left=left, right=right, n_samples=n_samples)\n",
    "        \n",
    "    def _best_split(self, X, y):\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "\n",
    "        n_feats = X.shape[1]  # total number of features\n",
    "\n",
    "        for feat_idx in range(n_feats):\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = None\n",
    "\n",
    "            # For numerical features, only check thresholds where y changes\n",
    "            if feat_idx in ['duration', 'pdays', 'balance']: \n",
    "                # Sort X_column and y based on the values in X_column\n",
    "                sorted_idx = np.argsort(X_column)\n",
    "                X_column_sorted, y_sorted = X_column[sorted_idx], y[sorted_idx]\n",
    "\n",
    "                # Identify points where the label of y changes\n",
    "                thresholds = []\n",
    "                for i in range(len(y_sorted) - 1):\n",
    "                    if y_sorted[i] != y_sorted[i + 1]:\n",
    "                        # Add the midpoint between two consecutive points where y changes\n",
    "                        thresholds.append((X_column_sorted[i] + X_column_sorted[i + 1]) / 2)\n",
    "            else:\n",
    "                # Otherwise, check for all unique values\n",
    "                thresholds = np.unique(X_column)\n",
    "\n",
    "            # Iterate through the identified thresholds\n",
    "            for thr in thresholds:\n",
    "                # Calculate information gain\n",
    "                gain = self._information_gain(y, X_column, thr)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "\n",
    "        return split_idx, split_threshold, best_gain\n",
    "\n",
    "    \n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        if self.criterion == \"gini\":\n",
    "            parent_impurity = self._gini(y)\n",
    "        else:\n",
    "            parent_impurity = self._entropy(y)\n",
    "        \n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        \n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        \n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs) / n, len(right_idxs) / n\n",
    "        \n",
    "        # Weighted average of the child impurities\n",
    "        if self.criterion == \"gini\":\n",
    "            return parent_impurity - (n_l * self._gini(y[left_idxs]) + n_r * self._gini(y[right_idxs]))\n",
    "        else:\n",
    "            return parent_impurity - (n_l * self._entropy(y[left_idxs]) + n_r * self._entropy(y[right_idxs]))\n",
    "        \n",
    "    def _split(self, X_column, split_thresh):\n",
    "        # Check if the feature is numerical (dtype is float or int)\n",
    "        if np.issubdtype(X_column.dtype, np.number):\n",
    "            # For numerical features\n",
    "            left_idx = np.argwhere(X_column <= split_thresh).flatten()\n",
    "            right_idx = np.argwhere(X_column > split_thresh).flatten()\n",
    "        else:\n",
    "            # For categorical features\n",
    "            left_idx = np.argwhere(X_column == split_thresh).flatten()\n",
    "            right_idx = np.argwhere(X_column != split_thresh).flatten()\n",
    "\n",
    "        return left_idx, right_idx\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "\n",
    "        # Ensure we have both class labels (y=0 and y=1) in ps\n",
    "        if len(ps) > 1:\n",
    "            # Apply class weight to y=1 if it exists\n",
    "            ps_weighted = np.copy(ps)\n",
    "            ps_weighted[1] *= self._class_weight\n",
    "        else:\n",
    "            # If there's only one class, no need to weight\n",
    "            ps_weighted = ps\n",
    "\n",
    "        return -np.sum([p * np.log2(p) for p in ps_weighted if p > 0])\n",
    "\n",
    "    \n",
    "    def _gini(self, y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist / len(y)\n",
    "\n",
    "        if len(ps) > 1:\n",
    "            # Apply class weight to y=1 if it exists\n",
    "            ps_weighted = np.copy(ps)\n",
    "            ps_weighted[1] *= self._class_weight\n",
    "        else:\n",
    "            # If there's only one class, no need to weight\n",
    "            ps_weighted = ps\n",
    "\n",
    "        return 1 - np.sum([p ** 2 for p in ps_weighted])\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def _traverse_tree(self, X, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        \n",
    "        feature_value = X[node.feature]\n",
    "        \n",
    "        if isinstance(feature_value, (int, float)):\n",
    "            # Numerical feature: go to left if X[feature] <= threshold, else go right\n",
    "            if feature_value <= node.threshold:\n",
    "                return self._traverse_tree(X, node.left)\n",
    "            else:\n",
    "                return self._traverse_tree(X, node.right)\n",
    "        else:\n",
    "            # Categorical feature: go to left if X[feature] == threshold, else go right\n",
    "            if feature_value == node.threshold:\n",
    "                return self._traverse_tree(X, node.left)\n",
    "            else:\n",
    "                return self._traverse_tree(X, node.right)\n",
    "\n",
    "\n",
    "\n",
    "    def get_max_depth(self):\n",
    "        def _depth(node):\n",
    "            if node.is_leaf_node():\n",
    "                return 0\n",
    "            return 1 + max(_depth(node.left), _depth(node.right))\n",
    "\n",
    "        return _depth(self.root)\n",
    "\n",
    "    def _count_leaves(self,node):\n",
    "        if node.is_leaf_node():\n",
    "            return 1\n",
    "        return self._count_leaves(node.left) + self._count_leaves(node.right)\n",
    "\n",
    "    def get_num_leaves(self):\n",
    "        return self._count_leaves(self.root)\n",
    "    \n",
    "    def _subtree_risk(self, node):\n",
    "        if node.is_leaf_node():\n",
    "            # The risk of a leaf node is its impurity weighted by its number of samples\n",
    "            return node.impurity * node.n_samples\n",
    "        \n",
    "        return self._subtree_risk(node.left) + self._subtree_risk(node.right)\n",
    "\n",
    "    def cost_complexity(self, node, alpha):\n",
    "        \"\"\"\n",
    "        Cost Complexity = Impurity (Risk) + alpha * Number of Leaves\n",
    "        \"\"\"\n",
    "        # Calculate the risk (impurity) of the subtree\n",
    "        risk = self._subtree_risk(node)\n",
    "        \n",
    "        # Count the number of leaves in the subtree\n",
    "        n_leaves = self._count_leaves(node)\n",
    "        \n",
    "        # Return the total cost complexity: risk + alpha * number of leaves\n",
    "        return risk + alpha * n_leaves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8934845803842265\n",
      "Training F1 Score:  0.2823078560783479\n",
      "Training Precision:  0.6597014925373135\n",
      "Training Recall:  0.1795774647887324\n",
      "CV Accuracy: 0.8873994638069705\n",
      "CV F1 Score: 0.24776119402985075\n",
      "CV Precision: 0.6148148148148148\n",
      "CV Recall: 0.15514018691588785\n",
      "Max Depth of the Tree: 20\n",
      "Number of Leaf Nodes: 54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def Precision(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "\n",
    "    return tp / (tp + np.sum((y_pred == 1) & (y_true == 0)))\n",
    "\n",
    "def Recall(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "\n",
    "    return tp / (tp + np.sum((y_true == 1) & (y_pred == 0)))\n",
    "\n",
    "def F1_score(y_true, y_pred):\n",
    "    p = Precision(y_true, y_pred)\n",
    "    r = Recall(y_true, y_pred)\n",
    "\n",
    "    return 2 * (p * r) / (p + r)\n",
    "\n",
    "def Accuracy(y_true, y_pred): \n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    return (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    # Set random seed for reproducibility\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    indices = np.arange(n_samples)  \n",
    "    np.random.shuffle(indices)      \n",
    "    \n",
    "    X_shuffled = X[indices]\n",
    "    y_shuffled = y[indices]\n",
    "    test_size_samples = int(test_size * n_samples)\n",
    "    \n",
    "    X_train = X_shuffled[:-test_size_samples]  \n",
    "    X_cv = X_shuffled[-test_size_samples:]\n",
    "    \n",
    "    y_train = y_shuffled[:-test_size_samples] \n",
    "    y_cv = y_shuffled[-test_size_samples:]    \n",
    "    \n",
    "    return X_train, X_cv, y_train, y_cv\n",
    "\n",
    "X = df[df.columns[:-1]].values\n",
    "y = df[df.columns[-1]].values\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.3, random_state=24)  \n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_cv, y_cv, test_size=0.67, random_state=42)\n",
    "\n",
    "# ros = RandomUnderSampler(random_state=42)\n",
    "# X_train_oversampled, y_train_oversampled = ros.fit_resample(X_train, y_train)\n",
    "# didn't produce good results, also SMOTE could not be applied to categorical features directly, so I just used class weight\n",
    "\n",
    "tree = DecisionTree(min_samples_split=19, max_depth=20,min_gain=0.02, criterion=\"gini\", _class_weight=2.4)\n",
    "# best set of parameters: 19,20,0.02,gini,2.4\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_pred = tree.predict(X_cv)\n",
    "\n",
    "train_accuracy=Accuracy(y_train, y_train_pred)\n",
    "train_f1= F1_score(y_train, y_train_pred)\n",
    "train_precision=Precision(y_train, y_train_pred)\n",
    "train_recall=Recall(y_train, y_train_pred)\n",
    "\n",
    "print(\"Training Accuracy: \", train_accuracy)\n",
    "print(\"Training F1 Score: \", train_f1)  \n",
    "print(\"Training Precision: \", train_precision)\n",
    "print(\"Training Recall: \", train_recall)\n",
    "\n",
    "cv_accuracy = Accuracy(y_cv, y_pred)\n",
    "cv_f1 = F1_score(y_cv, y_pred)\n",
    "cv_precision=Precision(y_cv, y_pred)\n",
    "cv_recall=Recall(y_cv, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy: {cv_accuracy}\")\n",
    "print(f\"CV F1 Score: {cv_f1}\")\n",
    "print(f\"CV Precision: {cv_precision}\")\n",
    "print(f\"CV Recall: {cv_recall}\")\n",
    "\n",
    "# cost_complexity_value = tree.cost_complexity(tree.root, alpha=0.01)\n",
    "# print(\"Cost Complexity of the tree:\", cost_complexity_value)\n",
    "\n",
    "max_depth = tree.get_max_depth()\n",
    "num_leaves = tree.get_num_leaves()\n",
    "\n",
    "print(f\"Max Depth of the Tree: {max_depth}\")\n",
    "print(f\"Number of Leaf Nodes: {num_leaves}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.3, random_state=24)\n",
    "\n",
    "# min_samples_split_values = np.arange(5, 40, 4)  \n",
    "# max_depth_values = np.arange(16, 25, 2)         \n",
    "# min_gain_values = np.arange(0.005, 0.036, 0.005) \n",
    "\n",
    "# best_f1_score = -1\n",
    "# best_params = None\n",
    "\n",
    "# # Perform grid search\n",
    "# for min_samples_split in min_samples_split_values:\n",
    "#     for max_depth in max_depth_values:\n",
    "#         for min_gain in min_gain_values:\n",
    "#             # Initialize the DecisionTree with current hyperparameters\n",
    "#             tree = DecisionTree(min_samples_split=min_samples_split,\n",
    "#                                 max_depth=max_depth,\n",
    "#                                 min_gain=min_gain,\n",
    "#                                 criterion=\"gini\", \n",
    "#                                 _class_weight=2.4)\n",
    "\n",
    "#             tree.fit(X_train, y_train)\n",
    "#             y_cv_pred = tree.predict(X_cv)\n",
    "#             f1 = F1_score(y_cv, y_cv_pred)\n",
    "            \n",
    "#             if f1 > best_f1_score:\n",
    "#                 best_f1_score = f1\n",
    "#                 best_params = {\n",
    "#                     'min_samples_split': min_samples_split,\n",
    "#                     'max_depth': max_depth,\n",
    "#                     'min_gain': min_gain\n",
    "#                 }\n",
    "\n",
    "# # Print the best hyperparameters and F1 score\n",
    "# print(f\"Best F1 Score: {best_f1_score}\")\n",
    "# print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth of the Tree: 7\n",
      "Number of Leaf Nodes: 8\n",
      "Test Accuracy:  0.8924837680202488\n",
      "Test F1 Score:  0.2945848375451263\n",
      "Test Precision:  0.631578947368421\n",
      "Test Recall:  0.192090395480226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check(node, X_node, y_node, tree, X_cv, y_cv, curr_recall, delta=0.125):\n",
    "    \n",
    "    if node.is_leaf_node() :\n",
    "        return\n",
    "    \n",
    "    left_idxs, right_idxs = tree._split(X_node[:, node.feature], node.threshold)\n",
    "\n",
    "    X_left, y_left = X_node[left_idxs], y_node[left_idxs]\n",
    "    X_right, y_right = X_node[right_idxs], y_node[right_idxs]\n",
    "    \n",
    "    check(node.left, X_left, y_left, tree, X_cv, y_cv, curr_recall, delta)\n",
    "    check(node.right, X_right, y_right, tree, X_cv, y_cv, curr_recall, delta)\n",
    "\n",
    "    if node.left.is_leaf_node() and node.right.is_leaf_node():  \n",
    "        # Temporarily prune this node\n",
    "        node.value = most_common_value(y_node)\n",
    "\n",
    "        y_pred_temp = tree.predict(X_cv)\n",
    "        temp_recall = Recall(y_cv, y_pred_temp)\n",
    "\n",
    "        if temp_recall < (1 - delta) * curr_recall:\n",
    "            # If pruning worsens recall significantly, restore it\n",
    "            node.value= None\n",
    "        else:\n",
    "            curr_recall = temp_recall\n",
    "            \n",
    "check(tree.root, X_train, y_train, tree, X_cv, y_cv, cv_recall, 0)\n",
    "\n",
    "max_depth = tree.get_max_depth()\n",
    "num_leaves = tree.get_num_leaves()\n",
    "\n",
    "print(f\"Max Depth of the Tree: {max_depth}\")\n",
    "print(f\"Number of Leaf Nodes: {num_leaves}\")\n",
    "\n",
    "y_test_pred = tree.predict(X_test)\n",
    "\n",
    "test_accuracy = Accuracy(y_test, y_test_pred)\n",
    "test_f1 = F1_score(y_test, y_test_pred)\n",
    "test_precision = Precision(y_test, y_test_pred)\n",
    "test_recall = Recall(y_test, y_test_pred)\n",
    "\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "print(\"Test F1 Score: \", test_f1)\n",
    "print(\"Test Precision: \", test_precision)\n",
    "print(\"Test Recall: \", test_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  age  marital  education default  balance housing loan   contact  day  \\\n",
      "0   1   30  married    primary      no     1787      no   no  cellular   19   \n",
      "1   2   33  married  secondary      no     4789     yes  yes  cellular   11   \n",
      "2   3   35   single   tertiary      no     1350     yes   no  cellular   16   \n",
      "3   4   30  married   tertiary      no     1476     yes  yes   unknown    3   \n",
      "4   5   59  married  secondary      no        0     yes   no   unknown    5   \n",
      "\n",
      "   duration  campaign  pdays  previous poutcome     job_group month_group  \n",
      "0        79         1     -1         0  unknown    Unemployed     sep-oct  \n",
      "1       220         1    339         4  failure   Blue-collar     may-aug  \n",
      "2       185         1    330         1  failure  white-collar         apr  \n",
      "3       199         4     -1         0  unknown  white-collar     may-aug  \n",
      "4       226         1     -1         0  unknown   Blue-collar     may-aug  \n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_excel(\"C:/Users/adity/A2 ML/Test.xlsx\")\n",
    "\n",
    "\n",
    "# Job group mapping\n",
    "job_group_mapping = {\n",
    "    'admin.': 'white-collar',\n",
    "    'management': 'white-collar',\n",
    "    'technician': 'white-collar',\n",
    "    'blue-collar': 'Blue-collar',\n",
    "    'services': 'Blue-collar',\n",
    "    'housemaid': 'Blue-collar',\n",
    "    'entrepreneur': 'Self-employed',\n",
    "    'self-employed': 'Self-employed',\n",
    "    'student': 'Student',\n",
    "    'unemployed': 'Unemployed',\n",
    "    'unknown': 'Unknown',\n",
    "    'retired': 'Retired'\n",
    "}\n",
    "\n",
    "df_test['job_group'] = df_test['job'].map(job_group_mapping)\n",
    "\n",
    "# Month group mapping\n",
    "month_group_mapping = {\n",
    "    'jan': 'jan-feb',\n",
    "    'feb': 'jan-feb',\n",
    "    'mar': 'mar',\n",
    "    'apr': 'apr',\n",
    "    'may': 'may-aug',  \n",
    "    'jun': 'may-aug',  \n",
    "    'jul': 'may-aug',  \n",
    "    'aug': 'may-aug',  \n",
    "    'sep': 'sep-oct',\n",
    "    'oct': 'sep-oct',\n",
    "    'nov': 'nov',\n",
    "    'dec': 'dec'\n",
    "}\n",
    "\n",
    "df_test['month_group'] = df_test['month'].map(month_group_mapping)\n",
    "\n",
    "# Drop the original 'job' and 'month' columns\n",
    "df_test = df_test.drop('job', axis=1)\n",
    "df_test = df_test.drop('month', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_test = df[df.columns[:]].values\n",
    "y_test_pred=tree.predict(X_test)\n",
    "print(y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
